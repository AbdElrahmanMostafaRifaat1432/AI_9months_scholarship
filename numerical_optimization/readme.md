# in this folder you will find implementations of many optimization teqniques such as gradient descent, momentum, NAG, adagrad, RmsProp, adam,  using batch, minibatch, stochastic 
# with also second order optimization techniques
